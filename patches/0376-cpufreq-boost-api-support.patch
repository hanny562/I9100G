Index: kernel/drivers/cpufreq/cpufreq.c
===================================================================
--- kernel.orig/drivers/cpufreq/cpufreq.c	2011-05-20 12:56:49.000000000 +0900
+++ kernel/drivers/cpufreq/cpufreq.c	2011-05-19 21:06:46.000000000 +0900
@@ -647,6 +647,34 @@
 	return policy->governor->show_setspeed(policy, buf);
 }
 
+static ssize_t show_boost_cpufreq(struct cpufreq_policy *policy, char *buf)
+{
+       if (!policy->governor || !policy->governor->boost_cpu_freq)
+               return sprintf(buf, "<unsupported>\n");
+
+       return sprintf(buf, "%d\n", 0);
+}
+
+static ssize_t store_boost_cpufreq(struct cpufreq_policy *policy,
+                                       const char *buf, size_t count)
+{
+       unsigned int boost = 0;
+       unsigned int ret;
+
+       if (!policy->governor)
+               return -EINVAL;
+
+       ret = sscanf(buf, "%u", &boost);
+       if (ret != 1)
+               return -EINVAL;
+
+       /* call policy-gov-boost functionality */
+       policy->governor->boost_cpu_freq(policy);
+
+       return count;
+}
+
+
 /**
  * show_scaling_driver - show the current cpufreq HW/BIOS limitation
  */
@@ -676,6 +704,7 @@
 cpufreq_freq_attr_rw(scaling_max_freq);
 cpufreq_freq_attr_rw(scaling_governor);
 cpufreq_freq_attr_rw(scaling_setspeed);
+cpufreq_freq_attr_rw(boost_cpufreq);
 
 static struct attribute *default_attrs[] = {
 	&cpuinfo_min_freq.attr,
@@ -689,6 +718,7 @@
 	&scaling_driver.attr,
 	&scaling_available_governors.attr,
 	&scaling_setspeed.attr,
+	&boost_cpufreq.attr,
 	NULL
 };
 
Index: kernel/drivers/cpufreq/cpufreq_hotplug.c
===================================================================
--- kernel.orig/drivers/cpufreq/cpufreq_hotplug.c	2011-05-20 12:56:49.000000000 +0900
+++ kernel/drivers/cpufreq/cpufreq_hotplug.c	2011-05-19 20:57:48.000000000 +0900
@@ -50,6 +50,8 @@
 static void do_dbs_timer(struct work_struct *work);
 static int cpufreq_governor_dbs(struct cpufreq_policy *policy,
 		unsigned int event);
+static int hotplug_boost(struct cpufreq_policy *policy);
+
 
 #ifndef CONFIG_CPU_FREQ_DEFAULT_GOV_HOTPLUG
 static
@@ -57,6 +59,7 @@
 struct cpufreq_governor cpufreq_gov_hotplug = {
        .name                   = "hotplug",
        .governor               = cpufreq_governor_dbs,
+       .boost_cpu_freq         = hotplug_boost,
        .owner                  = THIS_MODULE,
 };
 
@@ -68,6 +71,7 @@
 	struct delayed_work work;
 	struct cpufreq_frequency_table *freq_table;
 	int cpu;
+	unsigned int boost_applied:1;
 	/*
 	 * percpu mutex that serializes governor limit change with
 	 * do_dbs_timer invocation. We do not want do_dbs_timer to run
@@ -98,6 +102,7 @@
 	unsigned int *hotplug_load_history;
 	unsigned int ignore_nice;
 	unsigned int io_is_busy;
+	unsigned int boost_timeout;
 } dbs_tuners_ins = {
 	.sampling_rate =		DEFAULT_SAMPLING_PERIOD,
 	.up_threshold =			DEFAULT_UP_FREQ_MIN_LOAD,
@@ -108,6 +113,7 @@
 	.hotplug_load_index =		0,
 	.ignore_nice =			0,
 	.io_is_busy =			0,
+	.boost_timeout = 0,
 };
 
 /*
@@ -155,7 +161,21 @@
 show_one(hotplug_out_sampling_periods, hotplug_out_sampling_periods);
 show_one(ignore_nice_load, ignore_nice);
 show_one(io_is_busy, io_is_busy);
+show_one(boost_timeout, boost_timeout);
 
+static ssize_t store_boost_timeout(struct kobject *a, struct attribute *b,
+                                  const char *buf, size_t count)
+{
+    unsigned int input;
+    int ret;
+    ret = sscanf(buf, "%u", &input);
+    if (ret != 1)
+          return -EINVAL;
+    mutex_lock(&dbs_mutex);
+    dbs_tuners_ins.boost_timeout = input;
+    mutex_unlock(&dbs_mutex);
+    return count;
+}
 static ssize_t store_sampling_rate(struct kobject *a, struct attribute *b,
 				   const char *buf, size_t count)
 {
@@ -385,6 +405,7 @@
 define_one_global_rw(hotplug_out_sampling_periods);
 define_one_global_rw(ignore_nice_load);
 define_one_global_rw(io_is_busy);
+define_one_global_rw(boost_timeout);
 
 static struct attribute *dbs_attributes[] = {
 	&sampling_rate.attr,
@@ -395,6 +416,7 @@
 	&hotplug_out_sampling_periods.attr,
 	&ignore_nice_load.attr,
 	&io_is_busy.attr,
+	&boost_timeout.attr,
 	NULL
 };
 
@@ -564,12 +586,18 @@
 		container_of(work, struct cpu_dbs_info_s, work.work);
 	unsigned int cpu = dbs_info->cpu;
 
-	/* We want all related CPUs to do sampling nearly on same jiffy */
-	int delay = usecs_to_jiffies(dbs_tuners_ins.sampling_rate);
-	delay -= jiffies % delay;
-
+	int delay = 0;
 	mutex_lock(&dbs_info->timer_mutex);
-	dbs_check_cpu(dbs_info);
+	if (!dbs_info->boost_applied) {
+       dbs_check_cpu(dbs_info);
+       /* We want all related CPUs to do sampling nearly on same jiffy */
+       delay = usecs_to_jiffies(dbs_tuners_ins.sampling_rate);
+  } else {
+       delay = usecs_to_jiffies(dbs_tuners_ins.boost_timeout);
+       dbs_info->boost_applied = 0;
+       if (num_online_cpus() < 2)
+               cpu_up(1);
+  }
 	queue_delayed_work_on(cpu, khotplug_wq, &dbs_info->work, delay);
 	mutex_unlock(&dbs_info->timer_mutex);
 }
@@ -579,8 +607,9 @@
 	/* We want all related CPUs to do sampling nearly on same jiffy */
 	int delay = usecs_to_jiffies(dbs_tuners_ins.sampling_rate);
 	delay -= jiffies % delay;
-
 	INIT_DELAYED_WORK_DEFERRABLE(&dbs_info->work, do_dbs_timer);
+  if (!dbs_info->boost_applied)
+        delay = usecs_to_jiffies(dbs_tuners_ins.boost_timeout);
 	queue_delayed_work_on(dbs_info->cpu, khotplug_wq, &dbs_info->work,
 		delay);
 }
@@ -645,6 +674,9 @@
 				return rc;
 			}
 		}
+   if (!dbs_tuners_ins.boost_timeout)
+        dbs_tuners_ins.boost_timeout =  dbs_tuners_ins.sampling_rate * 30;
+
 		mutex_unlock(&dbs_mutex);
 
 		mutex_init(&this_dbs_info->timer_mutex);
@@ -682,6 +714,27 @@
 	}
 	return 0;
 }
+static int hotplug_boost(struct cpufreq_policy *policy)
+{
+       unsigned int cpu = policy->cpu;
+       struct cpu_dbs_info_s *this_dbs_info;
+
+       this_dbs_info = &per_cpu(hp_cpu_dbs_info, cpu);
+
+#if 0
+       /* Already at max? */
+       if (policy->cur == policy->max)
+               return;
+#endif
+
+       mutex_lock(&this_dbs_info->timer_mutex);
+       this_dbs_info->boost_applied = 1;
+       __cpufreq_driver_target(policy, policy->max,
+               CPUFREQ_RELATION_H);
+       mutex_unlock(&this_dbs_info->timer_mutex);
+
+       return 0;
+}
 
 static int __init cpufreq_gov_dbs_init(void)
 {
Index: kernel/drivers/cpufreq/cpufreq_ondemand.c
===================================================================
--- kernel.orig/drivers/cpufreq/cpufreq_ondemand.c	2011-05-20 12:56:49.000000000 +0900
+++ kernel/drivers/cpufreq/cpufreq_ondemand.c	2011-05-19 21:15:10.000000000 +0900
@@ -57,6 +57,8 @@
 static void do_dbs_timer(struct work_struct *work);
 static int cpufreq_governor_dbs(struct cpufreq_policy *policy,
 				unsigned int event);
+static int ondemand_boost(struct cpufreq_policy *policy);
+
 
 #ifndef CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND
 static
@@ -65,6 +67,7 @@
        .name                   = "ondemand",
        .governor               = cpufreq_governor_dbs,
        .max_transition_latency = TRANSITION_LATENCY_LIMIT,
+       .boost_cpu_freq         = ondemand_boost,
        .owner                  = THIS_MODULE,
 };
 
@@ -84,6 +87,7 @@
 	unsigned int freq_hi_jiffies;
 	int cpu;
 	unsigned int sample_type:1;
+	unsigned int boost_applied:1;
 	/*
 	 * percpu mutex that serializes governor limit change with
 	 * do_dbs_timer invocation. We do not want do_dbs_timer to run
@@ -110,11 +114,13 @@
 	unsigned int ignore_nice;
 	unsigned int powersave_bias;
 	unsigned int io_is_busy;
+	unsigned int boost_timeout;
 } dbs_tuners_ins = {
 	.up_threshold = DEF_FREQUENCY_UP_THRESHOLD,
 	.down_differential = DEF_FREQUENCY_DOWN_DIFFERENTIAL,
 	.ignore_nice = 0,
 	.powersave_bias = 0,
+	.boost_timeout = 0,
 };
 
 static inline cputime64_t get_cpu_idle_time_jiffy(unsigned int cpu,
@@ -261,6 +267,7 @@
 show_one(up_threshold, up_threshold);
 show_one(ignore_nice_load, ignore_nice);
 show_one(powersave_bias, powersave_bias);
+show_one(boost_timeout, boost_timeout);
 
 /*** delete after deprecation time ***/
 
@@ -282,11 +289,27 @@
 show_one_old(powersave_bias);
 show_one_old(sampling_rate_min);
 show_one_old(sampling_rate_max);
-
+show_one_old(boost_timeout);
 cpufreq_freq_attr_ro_old(sampling_rate_min);
 cpufreq_freq_attr_ro_old(sampling_rate_max);
 
 /*** delete after deprecation time ***/
+static ssize_t store_boost_timeout(struct kobject *a, struct attribute *b,
+                                  const char *buf, size_t count)
+{
+       unsigned int input;
+       int ret;
+       ret = sscanf(buf, "%u", &input);
+       if (ret != 1)
+               return -EINVAL;
+
+       mutex_lock(&dbs_mutex);
+       dbs_tuners_ins.boost_timeout = input;
+       mutex_unlock(&dbs_mutex);
+
+       return count;
+}
+
 
 static ssize_t store_sampling_rate(struct kobject *a, struct attribute *b,
 				   const char *buf, size_t count)
@@ -403,6 +426,8 @@
 define_one_global_rw(up_threshold);
 define_one_global_rw(ignore_nice_load);
 define_one_global_rw(powersave_bias);
+define_one_global_rw(boost_timeout);
+
 
 static struct attribute *dbs_attributes[] = {
 	&sampling_rate_max.attr,
@@ -412,6 +437,7 @@
 	&ignore_nice_load.attr,
 	&powersave_bias.attr,
 	&io_is_busy.attr,
+	&boost_timeout.attr,
 	NULL
 };
 
@@ -434,11 +460,13 @@
 write_one_old(up_threshold);
 write_one_old(ignore_nice_load);
 write_one_old(powersave_bias);
+write_one_old(boost_timeout);
 
 cpufreq_freq_attr_rw_old(sampling_rate);
 cpufreq_freq_attr_rw_old(up_threshold);
 cpufreq_freq_attr_rw_old(ignore_nice_load);
 cpufreq_freq_attr_rw_old(powersave_bias);
+cpufreq_freq_attr_rw_old(boost_timeout);
 
 static struct attribute *dbs_attributes_old[] = {
        &sampling_rate_max_old.attr,
@@ -447,6 +475,7 @@
        &up_threshold_old.attr,
        &ignore_nice_load_old.attr,
        &powersave_bias_old.attr,
+       &boost_timeout_old.attr,
        NULL
 };
 
@@ -617,17 +646,28 @@
 
 	/* Common NORMAL_SAMPLE setup */
 	dbs_info->sample_type = DBS_NORMAL_SAMPLE;
-	if (!dbs_tuners_ins.powersave_bias ||
-	    sample_type == DBS_NORMAL_SAMPLE) {
-		dbs_check_cpu(dbs_info);
-		if (dbs_info->freq_lo) {
-			/* Setup timer for SUB_SAMPLE */
-			dbs_info->sample_type = DBS_SUB_SAMPLE;
-			delay = dbs_info->freq_hi_jiffies;
+
+       /*
+        * check for any potential cpu boost request, sample at
+        * specified time by user.
+        */
+       if (!dbs_info->boost_applied) {
+               if (!dbs_tuners_ins.powersave_bias ||
+                   sample_type == DBS_NORMAL_SAMPLE) {
+                       dbs_check_cpu(dbs_info);
+                       if (dbs_info->freq_lo) {
+                               /* Setup timer for SUB_SAMPLE */
+                               dbs_info->sample_type = DBS_SUB_SAMPLE;
+                               delay = dbs_info->freq_hi_jiffies;
+                       }
+               } else {
+                       __cpufreq_driver_target(dbs_info->cur_policy,
+                               dbs_info->freq_lo, CPUFREQ_RELATION_H);
 		}
 	} else {
-		__cpufreq_driver_target(dbs_info->cur_policy,
-			dbs_info->freq_lo, CPUFREQ_RELATION_H);
+    delay = usecs_to_jiffies(dbs_tuners_ins.boost_timeout);
+           dbs_info->boost_applied = 0;
+
 	}
 	queue_delayed_work_on(cpu, kondemand_wq, &dbs_info->work, delay);
 	mutex_unlock(&dbs_info->timer_mutex);
@@ -735,6 +775,8 @@
 			dbs_tuners_ins.sampling_rate =
 				max(min_sampling_rate,
 				    latency * LATENCY_MULTIPLIER);
+       if (!dbs_tuners_ins.boost_timeout)
+                dbs_tuners_ins.boost_timeout =  dbs_tuners_ins.sampling_rate * 10;
 			dbs_tuners_ins.io_is_busy = should_io_be_busy();
 		}
 		mutex_unlock(&dbs_mutex);
@@ -770,6 +812,28 @@
 	}
 	return 0;
 }
+static int ondemand_boost(struct cpufreq_policy *policy)
+{
+       unsigned int cpu = policy->cpu;
+       struct cpu_dbs_info_s *this_dbs_info;
+
+       this_dbs_info = &per_cpu(od_cpu_dbs_info, cpu);
+
+#if 0
+       /* Already at max? */
+       if (policy->cur == policy->max)
+               return;
+#endif
+
+       mutex_lock(&this_dbs_info->timer_mutex);
+       this_dbs_info->boost_applied = 1;
+       __cpufreq_driver_target(policy, policy->max,
+               CPUFREQ_RELATION_H);
+       mutex_unlock(&this_dbs_info->timer_mutex);
+
+       return 0;
+}
+
 
 static int __init cpufreq_gov_dbs_init(void)
 {
Index: kernel/include/linux/cpufreq.h
===================================================================
--- kernel.orig/include/linux/cpufreq.h	2011-05-20 12:57:32.000000000 +0900
+++ kernel/include/linux/cpufreq.h	2011-05-19 21:16:32.000000000 +0900
@@ -178,8 +178,8 @@
 			will fallback to performance governor */
 	struct list_head	governor_list;
 	struct module		*owner;
+	int (*boost_cpu_freq)   (struct cpufreq_policy *policy);
 };
-
 /* pass a target to the cpufreq driver 
  */
 extern int cpufreq_driver_target(struct cpufreq_policy *policy,
