From: Mike Turquette <mturquette@ti.com>
Date: Thu, 19 May 2011 21:39:32 +0000 (-0500)
Subject: OMAP4: clock: DPLL cascading cannot invoke CPUfreq
X-Git-Url: http://git.omapzoom.org/?p=kernel%2Fomap.git;a=commitdiff_plain;h=3fe202bcdced848144bfcad91242d2629a44840b

OMAP4: clock: DPLL cascading cannot invoke CPUfreq

CPUfreq interfaces were used for controlling DPLL_MPU within DPLL cascading,
but this causes some race conditions in voltage layer/SmartReflex layer due
to competing calls to change voltages.

Instead, set DPLL_MPU clock rate via clock framework APIs so that only one
set of smart_reflex_enable/disable calls happen during DPLL cascading
sequence.

TODO: handle MPU local timer calibration from clock framework notifers
instead of from CPUfreq notifiers.

Change-Id: I38a6592878ae8f1e53aba0c8a06d1cadebb4cf30
Signed-off-by: Mike Turquette <mturquette@ti.com>
---

Index: kernel/arch/arm/kernel/smp_twd.c
===================================================================
--- kernel.orig/arch/arm/kernel/smp_twd.c	2011-05-27 23:13:46.898390322 +0900
+++ kernel/arch/arm/kernel/smp_twd.c	2011-05-27 23:26:50.729598152 +0900
@@ -250,6 +250,7 @@
 	if (!twd_timer_rate)
 		return 0;
 
+	/* FIXME change this to be a clock fwk notifier instead of CPUfreq */
 	if (cpufreq_register_notifier(&twd_cpufreq_notifier_block,
 				      CPUFREQ_TRANSITION_NOTIFIER))
 		pr_err("smp_twd: Failed to setup cpufreq notifier\n");
Index: kernel/arch/arm/mach-omap2/dpll-44xx.c
===================================================================
--- kernel.orig/arch/arm/mach-omap2/dpll-44xx.c	2011-05-27 23:13:47.887098070 +0900
+++ kernel/arch/arm/mach-omap2/dpll-44xx.c	2011-05-27 23:26:50.729598152 +0900
@@ -510,6 +510,7 @@
 
 void omap4_dpll_low_power_cascade_check_timer(struct work_struct *dwork)
 {
+	struct clk *dpll_mpu_m2_ck, *dpll_core_m2_ck;
 	int delay;
 
 	 /*
@@ -523,24 +524,15 @@
 	  * ASoC requests for DPLL cascade to be exited.
 	  */ 
 
-	if (num_online_cpus() > 1 ) {
-		delay = usecs_to_jiffies(LP_DELAY);
-		return schedule_delayed_work_on(0, &lpmode_work, delay);
- 	} 
+	dpll_mpu_m2_ck = clk_get(NULL, "dpll_mpu_m2_ck");
+	dpll_core_m2_ck = clk_get(NULL, "dpll_core_m2_ck");
 
-	/*
-	 * If CORE DPLL clock is at > 400MHz, then the 'check' function will 
-	 * schedule itself to be re-run in one second later to check again 
-	 * If CORE DPLL clock is < 400MHz or not.This will continue until 
-	 * CORE domain drop to OPP50.
-	 */	
-	if (clk_get_rate(dpll_core_clk) > 400000000) {
+	if (num_online_cpus() > 1 || clk_get_rate(dpll_core_m2_ck) > 400000000
+			|| clk_get_rate(dpll_mpu_m2_ck) > 300000000) {
 		delay = usecs_to_jiffies(LP_DELAY);
 		return schedule_delayed_work_on(0, &lpmode_work, delay);
-	} else {
-		pr_err("[%s] dpll_core_m2 rate=%d\n", __func__, clk_get_rate(dpll_core_clk));
+ 	} else
 		omap4_dpll_low_power_cascade_enter();
-	}
 }
 
 int omap4_dpll_low_power_cascade_check_entry()
@@ -632,17 +624,18 @@
 		goto out;
 	}
 
-     /* look up the three scalable voltage domains */
-     vdd_mpu = omap_voltage_domain_get("mpu");
-     vdd_iva = omap_voltage_domain_get("iva");
-     vdd_core = omap_voltage_domain_get("core");
-
-     /* disable SR adaptive voltage scaling while changing freq */
-     omap_smartreflex_disable(vdd_mpu);
-     omap_smartreflex_disable(vdd_iva);
-     omap_smartreflex_disable(vdd_core);	
+	omap4_lpmode = true;
+     
+	/* look up the three scalable voltage domains */
+	vdd_mpu = omap_voltage_domain_get("mpu");
+	vdd_iva = omap_voltage_domain_get("iva");
+	vdd_core = omap_voltage_domain_get("core");
+
+	/* disable SR adaptive voltage scaling while changing freq */
+	omap_smartreflex_disable(vdd_mpu);
+	omap_smartreflex_disable(vdd_iva);
+	omap_smartreflex_disable(vdd_core);	
 
-	 omap4_lpmode = true;
 
 	/* prevent DPLL_ABE & DPLL_CORE from idling */
 	omap3_dpll_deny_idle(dpll_abe_ck);
@@ -737,21 +730,8 @@
 	/* bypass DPLL_MPU */
 	state.dpll_mpu_ck_rate = dpll_mpu_ck->rate;
 
-	mpu_dev = omap2_get_mpuss_device();
-	opp = opp_find_voltage(mpu_dev, 928000, false);
-	opp_enable(opp);
-	state.mpu_opp = opp;
-
-	cp = cpufreq_cpu_get(0);
-	state.cpufreq_policy_cur_rate = cp->cur;
-	state.cpufreq_policy_min_rate = cp->min;
-	state.cpufreq_policy_max_rate = cp->max;
-
-	/* cpufreq takes in KHz */
-	cp->min = LP_196M_RATE / 1000;
-	cp->max = LP_196M_RATE / 1000;
-	cpufreq_cpu_put(cp);
-	ret = cpufreq_driver_target(cp, LP_196M_RATE / 1000, CPUFREQ_RELATION_H);
+	ret = clk_set_rate(dpll_mpu_ck,
+			dpll_mpu_ck->dpll_data->clk_bypass->rate);
 	if (ret) {
 		pr_err("%s: DPLL_MPU failed to enter Low Power bypass\n",
 				__func__);
@@ -926,14 +906,11 @@
 		return 0;
 	}
 
-	cp = cpufreq_cpu_get(0);
-	cp->min = state.cpufreq_policy_min_rate;
-	cp->max = state.cpufreq_policy_max_rate;
-	cpufreq_cpu_put(cp);
-	cpufreq_driver_target(cp, state.cpufreq_policy_cur_rate,
-			CPUFREQ_RELATION_H);
-	opp_disable(state.mpu_opp);
 
+	/* lock DPLL_MPU */
+	ret = clk_set_rate(dpll_mpu_ck, state.dpll_mpu_ck_rate);
+	if (ret)
+		pr_err("%s: DPLL_MPU failed to relock\n", __func__);
 	/* lock DPLL_IVA */
 	ret = clk_set_rate(dpll_iva_ck, state.dpll_iva_ck_rate);
 	if (ret)
@@ -984,8 +961,6 @@
 		pr_err("%s: failed restoring DPLL_CORE bypass clock parent\n",
 				__func__);
 
-	omap4_lpmode = false;
-
 	/* WA: allow DPLL_ABE_M3X2 clock to auto-gate */
 	omap4_prm_rmw_reg_bits(BIT(8), 0x0,
 			dpll_abe_m3x2_ck->clksel_reg);
@@ -1021,6 +996,8 @@
 		/*put back static dependency default vlaues during exit*/
 		__raw_writel(0x0000B0E0, OMAP4430_CM_MPU_STATICDEP);
 
+	omap4_lpmode = false;
+
 out:
 
 	return ret;
